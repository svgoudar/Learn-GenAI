{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db9a9eb8",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Deduplication and Noise Removal\n",
    "\n",
    "Deduplication and noise removal ensure that the input data for LLMs, RAG pipelines, and embeddings is **clean, unique, and semantically meaningful**. Poor-quality or repetitive data leads to weak retrieval, increased hallucinations, and degraded fine-tuning output.\n",
    "\n",
    "Both processes are core components of the ingestion pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "###  Deduplication\n",
    "\n",
    "Deduplication removes **exact or near-duplicate documents, chunks, sentences, or embeddings.**\n",
    "\n",
    "#### Why Deduplication Matters\n",
    "\n",
    "1. Prevents model **overfitting** to repeated content\n",
    "2. Reduces **vector DB size**\n",
    "3. Improves **retrieval diversity**\n",
    "4. Removes spam content\n",
    "5. Avoids **skewed fine-tuning** from repeated examples\n",
    "\n",
    "---\n",
    "\n",
    "### A. Types of Deduplication\n",
    "\n",
    "#### **1. Exact Deduplication**\n",
    "\n",
    "Checks if two documents or chunks are **identical**.\n",
    "\n",
    "Methods:\n",
    "\n",
    "* SHA256 hash of full text\n",
    "* Hash of normalized text\n",
    "* Fingerprinting (MinHash, SimHash)\n",
    "\n",
    "Use case: Remove multiple copies of same file.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Near-Duplicate Deduplication**\n",
    "\n",
    "Detects content that is *not identical* but *very similar*.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Same paragraph with slight punctuation changes\n",
    "* Duplicated bullet points\n",
    "* Repetitive logs or boilerplate\n",
    "\n",
    "Methods:\n",
    "\n",
    "* MinHash + Locality-Sensitive Hashing (LSH)\n",
    "* TF-IDF cosine similarity\n",
    "* Embedding similarity (e.g., >0.95 threshold)\n",
    "* SentenceTransformer similarity\n",
    "\n",
    "Use case: RAG ingestion, cleaning scraped websites.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Chunk-Level Deduplication**\n",
    "\n",
    "Even if documents differ, chunks may repeat.\n",
    "\n",
    "Detection:\n",
    "\n",
    "* Compare embeddings\n",
    "* Compare n-grams\n",
    "* Compare sentences\n",
    "\n",
    "Use case: Big PDFs, legal docs, policies, product manuals.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Cross-Document Deduplication**\n",
    "\n",
    "Identify repeated content across multiple sources.\n",
    "\n",
    "Example:\n",
    "FAQ answers repeated across sources.\n",
    "\n",
    "---\n",
    "\n",
    "### B. Deduplication Pipeline Example\n",
    "\n",
    "```\n",
    "Raw Text → Normalize → Hash → Exact Dedup → Embedding → Near Dedup → Store\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Noise Removal\n",
    "\n",
    "Noise removal removes content that is **irrelevant, meaningless, low-quality, or harmful**.\n",
    "\n",
    "#### Why Noise Removal Matters\n",
    "\n",
    "1. Reduces garbage chunks in RAG\n",
    "2. Improves embedding quality\n",
    "3. Prevents hallucinations\n",
    "4. Enhances chunk coherence\n",
    "5. Prevents indexing junk data\n",
    "\n",
    "---\n",
    "\n",
    "### A. Types of Noise\n",
    "\n",
    "#### **1. Boilerplate Noise**\n",
    "\n",
    "* Headers, footers\n",
    "* Navigation menus\n",
    "* Copyright lines\n",
    "* Page numbers\n",
    "* Repeated watermarks\n",
    "* “Back to top” links\n",
    "\n",
    "#### **2. OCR/Text Extraction Noise**\n",
    "\n",
    "* Misrecognized characters\n",
    "* Random symbols\n",
    "* Garbled text from scanned PDFs\n",
    "\n",
    "#### **3. Formatting Noise**\n",
    "\n",
    "* Excessive whitespace\n",
    "* HTML tags\n",
    "* Broken sentences\n",
    "\n",
    "#### **4. Semantic Noise**\n",
    "\n",
    "* Very short sentences with no meaning\n",
    "* Random paragraphs unrelated to topic\n",
    "* Duplicate disclaimers on every page\n",
    "\n",
    "#### **5. Log/Technical Noise**\n",
    "\n",
    "* Debug logs\n",
    "* Time stamps\n",
    "* Unstructured terminal outputs\n",
    "\n",
    "---\n",
    "\n",
    "### B. Noise Removal Techniques\n",
    "\n",
    "#### **1. Text Normalization**\n",
    "\n",
    "* Lowercasing\n",
    "* Removing non-printable characters\n",
    "* Removing repeated spaces\n",
    "* Fixing broken lines\n",
    "\n",
    "#### **2. HTML Cleaners**\n",
    "\n",
    "* Strip tags\n",
    "* Remove scripts, styles\n",
    "* Keep only semantic text\n",
    "\n",
    "#### **3. OCR Post-Processing**\n",
    "\n",
    "* Spell correction\n",
    "* Remove invalid Unicode sequences\n",
    "\n",
    "#### **4. Boilerplate Removal**\n",
    "\n",
    "* Use heuristic patterns\n",
    "* Domain-specific rules\n",
    "* Readability scores\n",
    "* Page template detection\n",
    "\n",
    "#### **5. Content-Length Filters**\n",
    "\n",
    "* Remove chunks below min length (e.g., < 20 characters)\n",
    "* Remove ultra-long garbage sections\n",
    "\n",
    "#### **6. ML-Based Noise Detection**\n",
    "\n",
    "* Classifiers trained to detect:\n",
    "\n",
    "  * Spam\n",
    "  * Junk paragraphs\n",
    "  * Unusable OCR text\n",
    "\n",
    "---\n",
    "\n",
    "### C. Noise Removal Pipeline Example\n",
    "\n",
    "```\n",
    "Raw Document → Clean HTML / OCR → Remove Boilerplate → Normalize → Filter by Quality → Chunk\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Combined Dedup + Noise Removal Workflow\n",
    "\n",
    "Below is a typical RAG ingestion sequence.\n",
    "\n",
    "```\n",
    "1. Parse document\n",
    "2. Normalize text\n",
    "3. Remove noise and boilerplate\n",
    "4. Deduplicate exact matches (hash-based)\n",
    "5. Generate temporary embeddings\n",
    "6. Deduplicate near-duplicates (embedding similarity)\n",
    "7. Keep only clean, unique chunks\n",
    "8. Generate final embeddings\n",
    "9. Store in vector DB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Example: Deduplication Implementation (Python)\n",
    "\n",
    "#### **Exact Dedup**\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "\n",
    "def hash_text(text):\n",
    "    normalized = \" \".join(text.split())\n",
    "    return hashlib.sha256(normalized.encode()).hexdigest()\n",
    "```\n",
    "\n",
    "#### **Near-Duplicate with Embeddings**\n",
    "\n",
    "```python\n",
    "def is_near_duplicate(emb1, emb2, threshold=0.95):\n",
    "    cos_sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1)*np.linalg.norm(emb2))\n",
    "    return cos_sim > threshold\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "### Deduplication\n",
    "\n",
    "* Removes exact and near copies\n",
    "* Prevents redundancy, improves retrieval quality\n",
    "\n",
    "### Noise Removal\n",
    "\n",
    "* Removes irrelevant, corrupted, low-quality text\n",
    "* Ensures chunks are clean and meaningful\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Raw Input Example (Realistic)\n",
    "\n",
    "```\n",
    "==================== PAGE 1 ====================\n",
    "Acme Product Manual – Version 4.2\n",
    "Copyright © 2024 Acme Corp.\n",
    "Page 1 of 32\n",
    "\n",
    "How to install the Acme Widget?\n",
    "--------------------------------\n",
    "Step 1: Unpack the device.\n",
    "Step 2: Connect the power cable.\n",
    "Step 3: Download the Acme setup app.\n",
    "\n",
    "Back to top\n",
    "================================================\n",
    "```\n",
    "\n",
    "Notice the noise:\n",
    "\n",
    "* Page number\n",
    "* Headers / footers\n",
    "* Copyright lines\n",
    "* “Back to top”\n",
    "* Hyphens and separators\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Noise Removal Demonstration\n",
    "\n",
    "#### Step A: Remove boilerplate\n",
    "\n",
    "```\n",
    "Acme Product Manual – Version 4.2\n",
    "\n",
    "How to install the Acme Widget?\n",
    "\n",
    "Step 1: Unpack the device.\n",
    "Step 2: Connect the power cable.\n",
    "Step 3: Download the Acme setup app.\n",
    "```\n",
    "\n",
    "Removed:\n",
    "\n",
    "* “Page 1 of 32”\n",
    "* “Copyright © 2024…”\n",
    "* “Back to top”\n",
    "* Page separators\n",
    "\n",
    "---\n",
    "\n",
    "#### Step B: Normalize text\n",
    "\n",
    "* Fix spacing\n",
    "* Remove repeated newlines\n",
    "* Lowercase if needed\n",
    "* Remove random symbols\n",
    "\n",
    "Result:\n",
    "\n",
    "```\n",
    "Acme Product Manual – Version 4.2\n",
    "How to install the Acme Widget?\n",
    "Step 1: Unpack the device.\n",
    "Step 2: Connect the power cable.\n",
    "Step 3: Download the Acme setup app.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Chunking\n",
    "\n",
    "```\n",
    "chunk_1:\n",
    "Acme Product Manual – Version 4.2\n",
    "\n",
    "chunk_2:\n",
    "How to install the Acme Widget?\n",
    "\n",
    "chunk_3:\n",
    "Step 1: Unpack the device.\n",
    "Step 2: Connect the power cable.\n",
    "Step 3: Download the Acme setup app.\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Exact Deduplication Demonstration\n",
    "\n",
    "Assume 3 documents contain the same installation steps.\n",
    "\n",
    "#### Before exact-dedup\n",
    "\n",
    "```\n",
    "chunk_3 from doc A\n",
    "chunk_3 from doc B\n",
    "chunk_3 from doc C\n",
    "```\n",
    "\n",
    "We hash each normalized chunk:\n",
    "\n",
    "```\n",
    "chunk_3 hash = 6f94c5c681bf3c...\n",
    "chunk_3 hash = 6f94c5c681bf3c...\n",
    "chunk_3 hash = 6f94c5c681bf3c...\n",
    "```\n",
    "\n",
    "All match → keep only 1.\n",
    "\n",
    "#### After exact-dedup\n",
    "\n",
    "```\n",
    "chunk_3 (unique)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Near-Duplicate Dedup (Embedding Similarity Demonstration)\n",
    "\n",
    "Assume we have two chunks:\n",
    "\n",
    "```\n",
    "chunk_1: \"Step 1: Unpack the device.\"\n",
    "chunk_2: \"Unpack the device first.\"\n",
    "```\n",
    "\n",
    "Not exact duplicates, but very similar.\n",
    "\n",
    "#### Embedding similarity\n",
    "\n",
    "```\n",
    "similarity(chunk_1, chunk_2) = 0.98\n",
    "```\n",
    "\n",
    "If threshold = **0.95**, treat as near-duplicates.\n",
    "\n",
    "Keep only the more complete or higher-quality version:\n",
    "\n",
    "```\n",
    "chunk_1 kept\n",
    "chunk_2 discarded\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Final Output After Cleaning + Deduplication\n",
    "\n",
    "**Final unique, noise-free chunks:**\n",
    "\n",
    "```\n",
    "1. Acme Product Manual – Version 4.2\n",
    "2. How to install the Acme Widget?\n",
    "3. Step 1: Unpack the device.\n",
    "   Step 2: Connect the power cable.\n",
    "   Step 3: Download the Acme setup app.\n",
    "```\n",
    "\n",
    "These three chunks are now clean, readable, and ready for embedding.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Full Demonstration Code (Python Example)\n",
    "\n",
    "```python\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------\n",
    "# Noise removal\n",
    "# ----------------------------------------\n",
    "def remove_noise(text):\n",
    "    boilerplate = [\n",
    "        r\"Page \\d+ of \\d+\",\n",
    "        r\"Copyright.*\",\n",
    "        r\"Back to top\",\n",
    "        r\"=+\",\n",
    "    ]\n",
    "\n",
    "    import re\n",
    "    cleaned = text\n",
    "    for p in boilerplate:\n",
    "        cleaned = re.sub(p, \"\", cleaned)\n",
    "\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = \" \".join(cleaned.split())  # normalize whitespace\n",
    "    return cleaned\n",
    "\n",
    "# ----------------------------------------\n",
    "# Exact deduplication\n",
    "# ----------------------------------------\n",
    "def text_hash(text):\n",
    "    normalized = \" \".join(text.split())\n",
    "    return hashlib.sha256(normalized.encode()).hexdigest()\n",
    "\n",
    "# ----------------------------------------\n",
    "# Near-duplicate check\n",
    "# ----------------------------------------\n",
    "def is_near_duplicate(emb1, emb2, threshold=0.95):\n",
    "    emb1, emb2 = np.array(emb1), np.array(emb2)\n",
    "    sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1)*np.linalg.norm(emb2))\n",
    "    return sim >= threshold\n",
    "\n",
    "# ----------------------------------------\n",
    "# Example demonstration\n",
    "# ----------------------------------------\n",
    "raw_text = \"\"\"\n",
    "==================== PAGE 1 ====================\n",
    "Acme Product Manual – Version 4.2\n",
    "Copyright © 2024 Acme Corp.\n",
    "Page 1 of 32\n",
    "\n",
    "How to install the Acme Widget?\n",
    "--------------------------------\n",
    "Step 1: Unpack the device.\n",
    "Step 2: Connect the power cable.\n",
    "Step 3: Download the Acme setup app.\n",
    "\n",
    "Back to top\n",
    "================================================\n",
    "\"\"\"\n",
    "\n",
    "clean_text = remove_noise(raw_text)\n",
    "print(\"Cleaned Text:\\n\", clean_text)\n",
    "\n",
    "# Example chunks\n",
    "chunks = [\n",
    "    \"Step 1: Unpack the device.\",\n",
    "    \"Unpack the device first.\"\n",
    "]\n",
    "\n",
    "# Fake embeddings for demonstration\n",
    "embeddings = [\n",
    "    np.random.rand(1536),\n",
    "    np.random.rand(1536) * 0.99   # artificially similar\n",
    "]\n",
    "\n",
    "print(\"Near duplicate:\", is_near_duplicate(embeddings[0], embeddings[1], 0.95))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Demonstration**\n",
    "\n",
    "### Noise Removal\n",
    "\n",
    "* Remove boilerplate\n",
    "* Normalize text\n",
    "* Clean OCR/HTML junk\n",
    "\n",
    "### Deduplication\n",
    "\n",
    "* Exact dedup → hash matching\n",
    "* Near-dedup → embedding similarity\n",
    "* Keep only clean, unique, high-quality chunks\n",
    "\n",
    "### Result\n",
    "\n",
    "You end up with **clean, meaningful, non-repetitive data** optimized for RAG and generative-AI training.\n",
    "\n",
    "If you want, I can demonstrate:\n",
    "\n",
    "* Full ingestion pipeline combining validator + dedup + chunker\n",
    "* Noise removal rules for PDFs, HTML, logs\n",
    "* Dedup logic for large datasets (1M+ documents)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
