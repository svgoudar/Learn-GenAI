{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adea56bd",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Storage Targets\n",
    "\n",
    "This covers **data lakes, warehouses, OLTP, OLAP**, and how each fits into a GenAI architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Why storage targets matter in GenAI ingestion\n",
    "\n",
    "A GenAI ingestion pipeline must store:\n",
    "\n",
    "* **raw data** (PDFs, HTML, text, tickets, logs)\n",
    "* **cleaned data**\n",
    "* **chunked data**\n",
    "* **embeddings**\n",
    "* **metadata and lineage**\n",
    "* **training/fine-tuning datasets**\n",
    "* **analytics metrics**\n",
    "* **audit logs and governance data**\n",
    "\n",
    "Each category has different **performance**, **cost**, **consistency**, and **query** requirements — hence different storage systems.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Storage targets and their roles\n",
    "\n",
    "#### **A. Data Lake**\n",
    "\n",
    "Examples: **S3, GCS, Azure Blob, MinIO, HDFS**\n",
    "\n",
    "#### Purpose in Generative-AI ingestion\n",
    "\n",
    "Data lake is the central **landing zone** for:\n",
    "\n",
    "* raw documents (PDF, HTML, DOCX, images)\n",
    "* OCR output\n",
    "* cleaned/normalized text\n",
    "* chunk files\n",
    "* embeddings (optional)\n",
    "* intermediate transformation artifacts\n",
    "* structured/unstructured hybrid data\n",
    "\n",
    "#### Why it’s used\n",
    "\n",
    "* Cheap, infinitely scalable\n",
    "* Stores any format (binary, text, parquet, JSONL)\n",
    "* Ideal for large unstructured corpora\n",
    "* Enables versioned storage (raw v1, parsed v2, chunks v3…)\n",
    "* Used for lineage + reproducibility\n",
    "\n",
    "#### Typical structures\n",
    "\n",
    "```\n",
    "/raw/2025/02/17/docs/*.pdf\n",
    "/clean/...\n",
    "/chunks/...\n",
    "/embeddings/...\n",
    "/fine_tuning/...\n",
    "/lineage/...\n",
    "```\n",
    "\n",
    "#### Tradeoff\n",
    "\n",
    "* Slower queries\n",
    "* Eventual consistency\n",
    "* Not suitable for real-time updates\n",
    "\n",
    "#### Summary\n",
    "\n",
    "**Best location for raw → processed → model-ready unstructured data.**\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Data Warehouse**\n",
    "\n",
    "Examples: **Snowflake, BigQuery, Redshift, Databricks SQL Warehouse**\n",
    "\n",
    "#### Purpose in Generative-AI ingestion\n",
    "\n",
    "Stores **structured and semi-structured analytics data**:\n",
    "\n",
    "* metadata for each document/chunk\n",
    "* quality scores\n",
    "* ingestion metrics (latency, throughput)\n",
    "* lineage tables\n",
    "* PII classification results\n",
    "* per-tenant access control metadata\n",
    "* training dataset catalogs\n",
    "* evaluation metrics\n",
    "\n",
    "#### Why it’s used\n",
    "\n",
    "* Fast SQL queries\n",
    "* Perfect for monitoring ingestion\n",
    "* Good for reporting and dashboards\n",
    "* Enforces strong consistency\n",
    "* Ideal for governance & compliance\n",
    "\n",
    "#### Typical tables\n",
    "\n",
    "```\n",
    "documents (doc_id, source, version, hash, ingest_time, pii_flags, classification)\n",
    "chunks    (chunk_id, doc_id, index, offsets, quality_score)\n",
    "embeddings_metadata (chunk_id, model_version, dim, timestamp)\n",
    "pipeline_runs\n",
    "pii_audit\n",
    "```\n",
    "\n",
    "#### Tradeoff\n",
    "\n",
    "* Not ideal for storing large vectors or binary content\n",
    "* More expensive than data lake\n",
    "\n",
    "#### Summary\n",
    "\n",
    "**Best for structured oversight, metadata, metrics, governance.**\n",
    "\n",
    "---\n",
    "\n",
    "### **C. OLTP Databases (Operational DBs)**\n",
    "\n",
    "Examples: **PostgreSQL, MySQL, CockroachDB, DynamoDB, Firestore**\n",
    "\n",
    "#### Purpose in GenAI ingestion\n",
    "\n",
    "Stores **fast-changing operational state**:\n",
    "\n",
    "* document registry (tracking ingest state)\n",
    "* user permissions\n",
    "* chunk status flags (parsed / deduped / embedded / indexed)\n",
    "* ingestion jobs & offsets\n",
    "* index versioning\n",
    "* active document revisions\n",
    "\n",
    "### Why it’s used\n",
    "\n",
    "* Fast read/write\n",
    "* Strong consistency\n",
    "* Low latency for pipeline control logic\n",
    "* Good for storing \"current state\" of ingestion\n",
    "\n",
    "#### Example table: `ingest_status`\n",
    "\n",
    "```\n",
    "doc_id\n",
    "status (raw, parsed, chunked, embedded, indexed)\n",
    "retry_count\n",
    "checksum\n",
    "last_updated\n",
    "```\n",
    "\n",
    "#### Tradeoff\n",
    "\n",
    "* Not suitable for large blobs\n",
    "* Not suitable for analytical queries over millions of rows\n",
    "\n",
    "#### Summary\n",
    "\n",
    "**Controls ingestion workflow and state tracking.**\n",
    "\n",
    "---\n",
    "\n",
    "### **D. OLAP Systems (Analytics Engines)**\n",
    "\n",
    "Examples: **ClickHouse, BigQuery, Druid, DuckDB, Databricks Delta Engine**\n",
    "\n",
    "#### Purpose in GenAI ingestion\n",
    "\n",
    "OLAP systems help run **heavy analytics on ingestion pipelines**, such as:\n",
    "\n",
    "* dedup analytics\n",
    "* embedding similarity metrics\n",
    "* ingestion performance\n",
    "* quality scoring pipelines\n",
    "* drift detection\n",
    "* curator dashboards (find bad chunks)\n",
    "\n",
    "#### Why it’s used\n",
    "\n",
    "* High throughput analytical scans\n",
    "* Excellent for time-series ingestion metrics\n",
    "* Useful for continuous evaluation of RAG quality\n",
    "\n",
    "#### Example use cases\n",
    "\n",
    "* “How many documents were ingested last 24 hours?”\n",
    "* “Which embeddings changed for model v3?”\n",
    "* “Which chunks produce lowest retrieval quality?”\n",
    "* “What is the near-duplicate ratio?”\n",
    "\n",
    "#### Tradeoff\n",
    "\n",
    "* Not for transactional ingestion state\n",
    "* Typically append-only\n",
    "\n",
    "#### Summary\n",
    "\n",
    "**Used for monitoring + analytics + QA over large ingestion volumes.**\n",
    "\n",
    "---\n",
    "\n",
    "### 3. How these storage systems work together in a GenAI pipeline\n",
    "\n",
    "#### Complete pipeline with correct storage choices\n",
    "\n",
    "```\n",
    "          (Raw PDFs, HTMLs)\n",
    "                  ↓\n",
    "            Data Lake (raw)\n",
    "                  ↓\n",
    "        Parsing / Cleaning cluster\n",
    "                  ↓\n",
    "            Data Lake (clean)\n",
    "                  ↓\n",
    "           Chunking & Dedup\n",
    "                  ↓\n",
    "            Data Lake (chunks)\n",
    "                  ↓\n",
    "    Embedding service (GPU / API)\n",
    "                  ↓\n",
    "             Vector Database\n",
    "            (Pinecone, Qdrant)\n",
    "                  ↓\n",
    "  Metadata to Data Warehouse + OLTP\n",
    "```\n",
    "\n",
    "#### Vector DB (important note)\n",
    "\n",
    "Vector DBs (e.g., Pinecone, Qdrant, Chroma) are **not** a general-purpose storage target; they store:\n",
    "\n",
    "* embeddings\n",
    "* chunk metadata\n",
    "\n",
    "But **raw content** must always live in the data lake to ensure reproducibility and lineage.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. A practical separation of concerns\n",
    "\n",
    "| Storage Type  | What goes here                                                   | Why                              |\n",
    "| ------------- | ---------------------------------------------------------------- | -------------------------------- |\n",
    "| **Data Lake** | raw files, cleaned text, chunks, embeddings (optional), datasets | cheap, scalable, versioned       |\n",
    "| **OLTP**      | ingestion state, retries, pipeline run states                    | fast updates, strong consistency |\n",
    "| **Warehouse** | metadata, lineage, audit logs, pipeline metrics                  | analytics, governance            |\n",
    "| **OLAP**      | large-scale query evaluation, ingestion performance analytics    | fast analytics                   |\n",
    "| **Vector DB** | embeddings + chunk metadata                                      | similarity search                |\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Design patterns for GenAI data ingestion using these storage targets\n",
    "\n",
    "#### Pattern A: “Medallion Architecture” for RAG\n",
    "\n",
    "```\n",
    "Bronze  (raw)   → Data Lake\n",
    "Silver  (clean) → Data Lake\n",
    "Gold    (chunks + metadata) → Data Lake + Warehouse\n",
    "Vectors (embeddings) → Vector DB\n",
    "```\n",
    "\n",
    "#### Pattern B: “Hybrid Control Plane”\n",
    "\n",
    "```\n",
    "OLTP = job control + statuses\n",
    "Warehouse = analytics + lineage\n",
    "Lake = data products\n",
    "Vector DB = retrieval engine\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Example metadata flow (showing each store)\n",
    "\n",
    "#### When processing a document:\n",
    "\n",
    "1. Raw PDF → **Data Lake** (`raw/`)\n",
    "2. Parsed text → **Data Lake** (`clean/`)\n",
    "3. Chunk metadata → **Warehouse** (`chunks table`)\n",
    "4. Chunk state → **OLTP** (`ingest_status`)\n",
    "5. Final embeddings → **Vector DB**\n",
    "6. Index version → **OLTP**\n",
    "7. Ingestion metrics → **OLAP**\n",
    "\n",
    "Everything is stored in the correct target.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. Practical guidance for choosing where to store what\n",
    "\n",
    "#### Store raw data in **data lake**\n",
    "\n",
    "Because:\n",
    "\n",
    "* reproducibility\n",
    "* low cost\n",
    "* independent of model version\n",
    "\n",
    "#### Store metadata + lineage in **warehouse**\n",
    "\n",
    "Because:\n",
    "\n",
    "* you need SQL analytics\n",
    "* governance + compliance\n",
    "\n",
    "#### Store ingestion state in **OLTP**\n",
    "\n",
    "Because:\n",
    "\n",
    "* low-latency workflow control\n",
    "\n",
    "#### Store embeddings only in **vector DB**\n",
    "\n",
    "Because:\n",
    "\n",
    "* optimized for similarity search\n",
    "\n",
    "#### Store analytics in **OLAP**\n",
    "\n",
    "Because:\n",
    "\n",
    "* fast analytical queries\n",
    "* time-series metrics\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "**Data Lake**\n",
    "\n",
    "* Master store for raw & processed unstructured data.\n",
    "* Best for versioning, lineage, cheap storage.\n",
    "\n",
    "**Data Warehouse**\n",
    "\n",
    "* Stores structured metadata, lineage, PII classifications, metrics.\n",
    "* Enables governance and analytics.\n",
    "\n",
    "**OLTP (operational store)**\n",
    "\n",
    "* Tracks ingest status, job state, retries, versioning.\n",
    "* Ensures consistent pipeline coordination.\n",
    "\n",
    "**OLAP**\n",
    "\n",
    "* High-performance analytics for quality, dedup, drift, performance metrics.\n",
    "\n",
    "**Vector DB**\n",
    "\n",
    "* Final store for embeddings + semantic metadata to enable RAG.\n",
    "\n",
    "Together, these form the complete storage architecture required for production GenAI ingestion."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
