{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4ca17e",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Data Validation and Quality Checks\n",
    "\n",
    "Data ingestion must ensure that **all data entering the system is accurate, complete, consistent, and safe**. Poor-quality data directly produces poor model performance, hallucinations, bias, and failures in downstream LLM/RAG pipelines.\n",
    "\n",
    "Below is a structured explanation.\n",
    "\n",
    "---\n",
    "\n",
    "###  What is Data Validation in Generative AI?\n",
    "\n",
    "Data validation ensures that incoming data **conforms to expected formats, schema, and integrity rules** before storage or processing.\n",
    "\n",
    "It checks:\n",
    "\n",
    "1. Structure\n",
    "2. Schema\n",
    "3. Format\n",
    "4. Completeness\n",
    "5. Consistency\n",
    "6. Safety\n",
    "7. Relevance\n",
    "\n",
    "---\n",
    "\n",
    "### What is Data Quality Checking?\n",
    "\n",
    "Data quality checks ensure that data is **usable and reliable** for generative AI tasks such as RAG, fine-tuning, embedding creation, and multimodal processing.\n",
    "\n",
    "It checks:\n",
    "\n",
    "1. Accuracy\n",
    "2. Noise level\n",
    "3. Duplicates\n",
    "4. Clarity\n",
    "5. Annotation correctness\n",
    "6. Toxic or unsafe content\n",
    "7. Content freshness\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Validation & Quality Checks During Ingestion\n",
    "\n",
    "Below is the end-to-end set of checks done in a typical generative-AI ingestion pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### **A. Structural Validation**\n",
    "\n",
    "#### 1. Schema Validation\n",
    "\n",
    "Check whether data matches the required schema.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "{ doc_id, text, metadata }\n",
    "```\n",
    "\n",
    "Missing any field → reject or send to error queue.\n",
    "\n",
    "#### 2. Type Validation\n",
    "\n",
    "* text must be string\n",
    "* vector must be float[]\n",
    "* images must be PNG/JPEG\n",
    "* metadata must be dict\n",
    "\n",
    "#### 3. Length Validation\n",
    "\n",
    "* Document length not zero\n",
    "* Token count within limits (e.g., max 8k tokens)\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Content Validation**\n",
    "\n",
    "#### 1. Language Detection\n",
    "\n",
    "Reject or route unsupported languages.\n",
    "\n",
    "#### 2. Encoding Check\n",
    "\n",
    "Ensure UTF-8; fix corrupted characters.\n",
    "\n",
    "#### 3. Format Validation\n",
    "\n",
    "* PDF correctly parsed\n",
    "* HTML cleaned\n",
    "* Audio duration valid\n",
    "* Image resolution valid\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Quality Checks**\n",
    "\n",
    "#### 1. Duplicate Detection\n",
    "\n",
    "Detect:\n",
    "\n",
    "* Duplicate documents\n",
    "* Duplicate chunks\n",
    "* Duplicate embeddings\n",
    "\n",
    "Use:\n",
    "\n",
    "* Hashing\n",
    "* Similarity search (FAISS, Chroma)\n",
    "\n",
    "#### 2. Noise Reduction\n",
    "\n",
    "Remove:\n",
    "\n",
    "* Boilerplate\n",
    "* Headers/footers\n",
    "* Repeated sentences\n",
    "* Random characters\n",
    "* Very short low-information text\n",
    "\n",
    "#### 3. Text Quality\n",
    "\n",
    "Check:\n",
    "\n",
    "* Grammar noise\n",
    "* Missing punctuation\n",
    "* Nonsensical phrases\n",
    "* Empty paragraphs\n",
    "\n",
    "#### 4. Dead Links / Invalid Paths\n",
    "\n",
    "Validate URLs, file paths, blob storage references.\n",
    "\n",
    "---\n",
    "\n",
    "### **D. Safety Validation**\n",
    "\n",
    "#### 1. Toxicity / Hate / Violence Filters\n",
    "\n",
    "Mark or remove harmful or unsafe content.\n",
    "\n",
    "#### 2. PII Detection\n",
    "\n",
    "Detect:\n",
    "\n",
    "* Phone numbers\n",
    "* Emails\n",
    "* Identifiable personal info\n",
    "  Decide to mask, remove, or keep based on usage.\n",
    "\n",
    "#### 3. IP / Copyright Check\n",
    "\n",
    "Remove copyrighted text if disallowed.\n",
    "\n",
    "---\n",
    "\n",
    "### **E. Semantic Validation**\n",
    "\n",
    "#### 1. Relevance Checking\n",
    "\n",
    "Ensure document is relevant to domain.\n",
    "\n",
    "Example:\n",
    "A legal RAG system should not ingest random blogs.\n",
    "\n",
    "#### 2. Chunk-Level Coherence\n",
    "\n",
    "Chunk should contain:\n",
    "\n",
    "* Complete sentences\n",
    "* No abrupt cutoff\n",
    "* No mixed topics\n",
    "\n",
    "#### 3. Metadata-Content Alignment\n",
    "\n",
    "Check if metadata matches content.\n",
    "\n",
    "Example:\n",
    "metadata.language = \"en\" but content is French → reject.\n",
    "\n",
    "---\n",
    "\n",
    "### **F. Embedding Validation (for RAG)**\n",
    "\n",
    "#### 1. Vector Dimension Check\n",
    "\n",
    "Correct dimensionality (e.g., 1536, 768, 3072).\n",
    "\n",
    "#### 2. Vector Range Check\n",
    "\n",
    "Vector values not infinite or NaN.\n",
    "\n",
    "#### 3. Vector–Text Linking\n",
    "\n",
    "Every embedding must map to a valid chunk.\n",
    "\n",
    "---\n",
    "\n",
    "### **G. Versioning Checks**\n",
    "\n",
    "#### 1. Schema Version\n",
    "\n",
    "Enforce schema_version = v1, v2, etc.\n",
    "\n",
    "#### 2. Embedding Model Version\n",
    "\n",
    "Ensure embeddings are created using correct model.\n",
    "\n",
    "---\n",
    "\n",
    "### **H. Monitoring & Logging**\n",
    "\n",
    "#### 1. Data Quality Metrics\n",
    "\n",
    "* Fill rate\n",
    "* Error rate\n",
    "* Duplicate rate\n",
    "* Quality score distribution\n",
    "\n",
    "#### 2. Data Drift Detection\n",
    "\n",
    "Identify changes in:\n",
    "\n",
    "* Language patterns\n",
    "* Tone\n",
    "* Topic distribution\n",
    "* Sentence length\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Ingestion Pipeline with Validation\n",
    "\n",
    "```\n",
    "Raw Data → Parser → Schema Validation → Content Quality Checks\n",
    "        → Safety Filters → Deduplication → Chunking\n",
    "        → Embedding Generation → Embedding Validation → Storage\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "Data validation and quality checks ensure:\n",
    "\n",
    "* Clean input\n",
    "* Reliable text\n",
    "* Safe content\n",
    "* Accurate embeddings\n",
    "* High-quality chunks\n",
    "* Better LLM/RAG performance\n",
    "\n",
    "Below are **all three demonstrations**:\n",
    "\n",
    "### 1. Complete Validation Ruleset (Structured)\n",
    "\n",
    "#### **A. Structural Validation**\n",
    "\n",
    "1. `doc_id` must be present and unique\n",
    "2. `text` must be non-empty\n",
    "3. `metadata` must be a dictionary\n",
    "4. File formats must be valid:\n",
    "\n",
    "   * PDFs must parse correctly\n",
    "   * Images must be PNG/JPEG\n",
    "   * Audio must be WAV/MP3\n",
    "5. Length rules:\n",
    "\n",
    "   * Text length ≥ 20 characters\n",
    "   * Token count ≤ configured limit\n",
    "6. Embedding dimension must match model (e.g., 1536)\n",
    "\n",
    "---\n",
    "\n",
    "#### **B. Content Quality Rules**\n",
    "\n",
    "1. Remove boilerplate (headers, footers, navigation links)\n",
    "2. Remove duplicate sentences\n",
    "3. Reject documents with gibberish, corrupted text, random characters\n",
    "4. Ensure clear sentence boundaries\n",
    "5. Reject documents with excessive empty lines or whitespace\n",
    "\n",
    "---\n",
    "\n",
    "#### **C. Safety Rules**\n",
    "\n",
    "1. Detect and remove/flag:\n",
    "\n",
    "   * Hate speech\n",
    "   * Violence\n",
    "   * Self-harm content\n",
    "   * NSFW content\n",
    "2. PII detection:\n",
    "\n",
    "   * Mask email, phone, address if policy requires\n",
    "3. Copyright/IP checks\n",
    "\n",
    "---\n",
    "\n",
    "#### **D. Relevance Rules**\n",
    "\n",
    "1. Document must belong to the selected domain (finance, legal, healthcare)\n",
    "2. Reject off-topic content\n",
    "3. Enforce metadata-content alignment (metadata.language must match detected language)\n",
    "\n",
    "---\n",
    "\n",
    "#### **E. Embedding Validation Rules**\n",
    "\n",
    "1. No NaN or infinite values\n",
    "2. Confirm vector dimension\n",
    "3. Embedding must link to a valid chunk\n",
    "4. Reject embeddings produced with obsolete model versions\n",
    "\n",
    "---\n",
    "\n",
    "#### **F. Metadata Validation**\n",
    "\n",
    "1. Required fields: `source`, `language`, `timestamp`\n",
    "2. Validate timestamp format\n",
    "3. Validate language using fastText/CLD3\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Python Class for Validation (Production-Style Example)\n",
    "\n",
    "```python\n",
    "import re\n",
    "import langdetect\n",
    "import numpy as np\n",
    "\n",
    "class DocumentValidator:\n",
    "    def __init__(self, embedding_dim=1536, allowed_langs=[\"en\"]):\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.allowed_langs = allowed_langs\n",
    "\n",
    "    # ---------------------------\n",
    "    # Structural Validation\n",
    "    # ---------------------------\n",
    "    def validate_schema(self, doc):\n",
    "        required_fields = [\"doc_id\", \"text\", \"metadata\"]\n",
    "        for f in required_fields:\n",
    "            if f not in doc:\n",
    "                return False, f\"Missing field: {f}\"\n",
    "\n",
    "        if not isinstance(doc[\"metadata\"], dict):\n",
    "            return False, \"metadata must be a dictionary\"\n",
    "\n",
    "        if len(doc[\"text\"].strip()) < 20:\n",
    "            return False, \"Text too short\"\n",
    "\n",
    "        return True, \"OK\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # Language Validation\n",
    "    # ---------------------------\n",
    "    def validate_language(self, text):\n",
    "        try:\n",
    "            lang = langdetect.detect(text)\n",
    "            if lang not in self.allowed_langs:\n",
    "                return False, f\"Unsupported language: {lang}\"\n",
    "            return True, \"OK\"\n",
    "        except:\n",
    "            return False, \"Language detection failed\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # Duplicate / Noise Check\n",
    "    # ---------------------------\n",
    "    def has_gibberish(self, text):\n",
    "        nonsense_pattern = r\"[A-Za-z]{20,}\"  # very long unbroken letters\n",
    "        return bool(re.search(nonsense_pattern, text))\n",
    "\n",
    "    # ---------------------------\n",
    "    # Safety Check (basic)\n",
    "    # ---------------------------\n",
    "    def contains_disallowed_content(self, text):\n",
    "        unsafe_keywords = [\"kill\", \"suicide\", \"bomb\", \"hate\"]\n",
    "        for kw in unsafe_keywords:\n",
    "            if kw.lower() in text.lower():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # ---------------------------\n",
    "    # Embedding Validation\n",
    "    # ---------------------------\n",
    "    def validate_embedding(self, vector):\n",
    "        arr = np.array(vector)\n",
    "        if arr.shape[0] != self.embedding_dim:\n",
    "            return False, \"Incorrect embedding dimension\"\n",
    "        if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "            return False, \"Embedding contains invalid values\"\n",
    "        return True, \"OK\"\n",
    "\n",
    "    # ---------------------------\n",
    "    # Master Validation Function\n",
    "    # ---------------------------\n",
    "    def validate(self, doc, embedding=None):\n",
    "        # Schema\n",
    "        ok, msg = self.validate_schema(doc)\n",
    "        if not ok:\n",
    "            return False, msg\n",
    "\n",
    "        # Language\n",
    "        ok, msg = self.validate_language(doc[\"text\"])\n",
    "        if not ok:\n",
    "            return False, msg\n",
    "\n",
    "        # Gibberish check\n",
    "        if self.has_gibberish(doc[\"text\"]):\n",
    "            return False, \"Contains noise/gibberish\"\n",
    "\n",
    "        # Safety\n",
    "        if self.contains_disallowed_content(doc[\"text\"]):\n",
    "            return False, \"Unsafe content detected\"\n",
    "\n",
    "        # Embedding\n",
    "        if embedding is not None:\n",
    "            ok, msg = self.validate_embedding(embedding)\n",
    "            if not ok:\n",
    "                return False, msg\n",
    "\n",
    "        return True, \"Document is valid\"\n",
    "```\n",
    "\n",
    "This can be plugged directly into a RAG ingestion pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Full Architecture Diagram (Text Representation)\n",
    "\n",
    "```\n",
    "                  ┌──────────────────────────────┐\n",
    "                  │          RAW DATA            │\n",
    "                  │ (pdf, html, images, audio)   │\n",
    "                  └──────────────┬───────────────┘\n",
    "                                 │\n",
    "                                 ▼\n",
    "                ┌──────────────────────────────────┐\n",
    "                │          PARSING LAYER            │\n",
    "                │ PDF parsers, OCR, HTML cleaners   │\n",
    "                └──────────────┬───────────────────┘\n",
    "                               │\n",
    "                               ▼\n",
    "         ┌─────────────────────────────────────────────────┐\n",
    "         │         DATA VALIDATION & QUALITY CHECKS         │\n",
    "         │  - Schema Validation                             │\n",
    "         │  - Format Validation                             │\n",
    "         │  - Language Detection                            │\n",
    "         │  - Noise & Boilerplate Removal                   │\n",
    "         │  - Duplicate Detection                           │\n",
    "         │  - Safety Filters                                │\n",
    "         │  - Metadata Validation                           │\n",
    "         └──────────────┬──────────────────────────────────┘\n",
    "                        │\n",
    "                        ▼\n",
    "             ┌──────────────────────────────┐\n",
    "             │      CLEAN & VALID DATA      │\n",
    "             └──────────────┬───────────────┘\n",
    "                            │\n",
    "                            ▼\n",
    "    ┌────────────────────────────────────────────────────────┐\n",
    "    │                 CHUNKING & NORMALIZATION               │\n",
    "    │  - Split into semantic chunks                          │\n",
    "    │  - Remove irrelevant parts                             │\n",
    "    │  - Add chunk metadata                                  │\n",
    "    └───────────────┬──────────────────────────────────────┘\n",
    "                    │\n",
    "                    ▼\n",
    "         ┌──────────────────────────────────────────┐\n",
    "         │           EMBEDDING GENERATION           │\n",
    "         │    OpenAI / local embedding models        │\n",
    "         └───────────────┬──────────────────────────┘\n",
    "                         │\n",
    "                         ▼\n",
    "              ┌─────────────────────────────┐\n",
    "              │     EMBEDDING VALIDATION    │\n",
    "              │ - Dimension check            │\n",
    "              │ - NaN/Inf check              │\n",
    "              │ - Version match              │\n",
    "              └─────────────┬──────────────┘\n",
    "                            │\n",
    "                            ▼\n",
    "            ┌─────────────────────────────────┐\n",
    "            │      VECTOR STORE / DATABASE    │\n",
    "            │  (FAISS / Chroma / Pinecone)    │\n",
    "            └─────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
