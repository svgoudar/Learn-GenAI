{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8655223a",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Change Data Capture (CDC)\n",
    "\n",
    "**Change Data Capture (CDC) in LLM workflows** refers to detecting and processing **only the data that has changed**—instead of reprocessing the entire dataset—so your LLM, embeddings, vector store, or RAG system stays up-to-date efficiently.\n",
    "\n",
    "LLMs themselves don’t *perform* CDC, but CDC is used in **data pipelines feeding LLMs**, especially in **continuous ingestion RAG pipelines**, enterprise systems, and real-time AI applications.\n",
    "\n",
    "---\n",
    "\n",
    "### What CDC Means\n",
    "\n",
    "CDC = A technique that captures **insert**, **update**, and **delete** events happening in a source system (e.g., database, files, logs) and sends only the changed portions to downstream systems.\n",
    "\n",
    "---\n",
    "\n",
    "### Why CDC Matters in LLM / RAG Systems\n",
    "\n",
    "LLM pipelines often require:\n",
    "\n",
    "* Rebuilding embeddings\n",
    "* Updating indexes\n",
    "* Keeping vector stores synced with source data\n",
    "* Updating RAG responses based on newest information\n",
    "\n",
    "Without CDC:\n",
    "\n",
    "* You would reprocess the entire dataset (slow and expensive).\n",
    "* Embeddings would repeatedly be regenerated.\n",
    "* Vector DBs would grow incorrectly or become stale.\n",
    "\n",
    "With CDC:\n",
    "\n",
    "* Only changed records get re-embedded\n",
    "* Vector stores update incrementally\n",
    "* RAG answers stay aligned with the latest data\n",
    "\n",
    "---\n",
    "\n",
    "### How CDC Integrates with LLM Pipelines\n",
    "\n",
    "Below is the typical flow:\n",
    "\n",
    "#### **Source Database → CDC Engine → Event Stream → LLM Pipeline → Vector Store**\n",
    "\n",
    "CDC engine examples:\n",
    "\n",
    "* Debezium\n",
    "* PostgreSQL WAL\n",
    "* MySQL binlog\n",
    "* Kafka Connect CDC\n",
    "* DynamoDB Streams\n",
    "* Snowflake Streams\n",
    "\n",
    "### LLM pipeline consumes:\n",
    "\n",
    "* New rows → generate embeddings → insert into vector DB\n",
    "* Updated rows → regenerate embeddings → update record\n",
    "* Deleted rows → remove embeddings from vector DB\n",
    "\n",
    "This keeps the knowledge base **real-time**, **consistent**, and **fresh**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: CDC in a Practical RAG Setup**\n",
    "\n",
    "#### When a new customer ticket is added:\n",
    "\n",
    "1. CDC captures the new row\n",
    "2. Sends message to Kafka topic\n",
    "3. Worker reads event, embeds text\n",
    "4. Adds to FAISS / Chroma / Pinecone\n",
    "5. LLM instantly uses the updated index\n",
    "\n",
    "#### When a ticket is updated:\n",
    "\n",
    "1. CDC captures UPDATE\n",
    "2. Worker re-embeds only the changed content\n",
    "3. Index entry is replaced\n",
    "\n",
    "#### When a ticket is deleted:\n",
    "\n",
    "1. CDC captures DELETE\n",
    "2. Worker removes the vector entry\n",
    "\n",
    "---\n",
    "\n",
    "### Benefits of Using CDC for LLM\n",
    "\n",
    "#### Fresh, real-time knowledge\n",
    "\n",
    "LLMs often answer questions about:\n",
    "\n",
    "* Logs\n",
    "* CRM data\n",
    "* Tickets\n",
    "* Policies\n",
    "* Product catalogs\n",
    "\n",
    "CDC ensures answers reflect the latest state.\n",
    "\n",
    "#### Lower cost\n",
    "\n",
    "Embedding large datasets repeatedly is expensive.\n",
    "CDC eliminates unnecessary reprocessing.\n",
    "\n",
    "#### Better consistency\n",
    "\n",
    "Vector store and source DB stay aligned.\n",
    "\n",
    "#### Event-driven architecture\n",
    "\n",
    "Fits perfectly with streaming ingestion + LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "**Example Code Flow (High-Level)**\n",
    "\n",
    "```python\n",
    "def handle_cdc_event(event):\n",
    "    if event.type == \"insert\":\n",
    "        embed_and_upsert(event.data)\n",
    "    elif event.type == \"update\":\n",
    "        embed_and_update(event.data)\n",
    "    elif event.type == \"delete\":\n",
    "        vector_db.delete(event.primary_key)\n",
    "```\n",
    "\n",
    "This runs inside a worker subscribed to a CDC stream.\n",
    "\n",
    "---\n",
    "\n",
    "**Where CDC + LLM is used**\n",
    "\n",
    "* Enterprise knowledge bases\n",
    "* Customer support copilots\n",
    "* Real-time analytics assistants\n",
    "* AI over ERP/CRM systems\n",
    "* Compliance and audit LLMs\n",
    "* Automated document intelligence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4792737b",
   "metadata": {},
   "source": [
    "### Demonstration\n",
    "Below is a **clean, production-style demonstration** of **CDC using Debezium + Kafka → Embeddings → Vector DB → RAG**.\n",
    "This is the most commonly used real-time architecture for enterprise LLM systems.\n",
    "\n",
    "The explanation is **fully structured**, followed by **complete code** for:\n",
    "\n",
    "* Debezium + Kafka setup\n",
    "* CDC event stream\n",
    "* Python consumer\n",
    "* Embedding + vector DB updates\n",
    "* RAG answering\n",
    "* Live incremental knowledge refresh\n",
    "\n",
    "---\n",
    "\n",
    "#### Architecture (Debezium → Kafka → Python → RAG Pipeline)\n",
    "\n",
    "```\n",
    "        ┌──────────┐\n",
    "        │ Postgres │\n",
    "        │  Table   │\n",
    "        └─────┬────┘\n",
    "              │  CDC (WAL)\n",
    "              ▼\n",
    "       ┌─────────────┐\n",
    "       │  Debezium   │\n",
    "       │ PostgreSQL  │\n",
    "       └──────┬──────┘\n",
    "              │ Change Events\n",
    "              ▼\n",
    "       ┌─────────────┐\n",
    "       │   Kafka     │\n",
    "       │   Topic     │\n",
    "       └──────┬──────┘\n",
    "              │ JSON CDC Payload\n",
    "              ▼\n",
    "      ┌────────────────┐\n",
    "      │ Python Worker  │\n",
    "      │ (Kafka Consumer)\n",
    "      └──────┬─────────┘\n",
    "             │\n",
    "             ├── Insert → embed → upsert vector DB\n",
    "             ├── Update → re-embed → update vector DB\n",
    "             └── Delete → remove vector from index\n",
    "             ▼\n",
    "       ┌──────────────┐\n",
    "       │ Vector Store │\n",
    "       └──────┬───────┘\n",
    "              ▼\n",
    "         ┌──────────┐\n",
    "         │   RAG    │\n",
    "         └──────────┘\n",
    "```\n",
    "\n",
    "This ensures **real-time synchronization** between Postgres and your vector database.\n",
    "\n",
    "---\n",
    "\n",
    "#### Debezium + Kafka Setup (docker-compose)\n",
    "\n",
    "Create a file named **docker-compose.yml**:\n",
    "\n",
    "```yaml\n",
    "version: '3.7'\n",
    "services:\n",
    "  zookeeper:\n",
    "    image: confluentinc/cp-zookeeper:7.4.0\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 2181\n",
    "\n",
    "  kafka:\n",
    "    image: confluentinc/cp-kafka:7.4.0\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    environment:\n",
    "      KAFKA_BROKER_ID: 1\n",
    "      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "\n",
    "  postgres:\n",
    "    image: debezium/example-postgres:2.5\n",
    "    environment:\n",
    "      POSTGRES_USER: postgres\n",
    "      POSTGRES_PASSWORD: postgres\n",
    "      POSTGRES_DB: mydb\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "\n",
    "  debezium:\n",
    "    image: debezium/connect:2.5\n",
    "    depends_on:\n",
    "      - kafka\n",
    "      - postgres\n",
    "    ports:\n",
    "      - \"8083:8083\"\n",
    "    environment:\n",
    "      BOOTSTRAP_SERVERS: kafka:9092\n",
    "      GROUP_ID: 1\n",
    "      CONFIG_STORAGE_TOPIC: debezium_config\n",
    "      OFFSET_STORAGE_TOPIC: debezium_offsets\n",
    "      STATUS_STORAGE_TOPIC: debezium_status\n",
    "```\n",
    "\n",
    "Start it:\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Register Debezium Postgres Connector\n",
    "\n",
    "Run:\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:8083/connectors -H \"Content-Type: application/json\" -d '{\n",
    "  \"name\": \"pg-connector\",\n",
    "  \"config\": {\n",
    "    \"connector.class\": \"io.debezium.connector.postgresql.PostgresConnector\",\n",
    "    \"database.hostname\": \"postgres\",\n",
    "    \"database.port\": \"5432\",\n",
    "    \"database.user\": \"postgres\",\n",
    "    \"database.password\": \"postgres\",\n",
    "    \"database.dbname\": \"mydb\",\n",
    "    \"database.server.name\": \"pg\",\n",
    "    \"plugin.name\": \"pgoutput\",\n",
    "    \"slot.name\": \"debezium\",\n",
    "    \"table.include.list\": \"public.tickets\"\n",
    "  }\n",
    "}'\n",
    "```\n",
    "\n",
    "This sends CDC events into Kafka topic:\n",
    "\n",
    "```\n",
    "pg.public.tickets\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Prepare the Postgres Table\n",
    "\n",
    "```sql\n",
    "CREATE TABLE tickets (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    text TEXT NOT NULL,\n",
    "    updated_at TIMESTAMP DEFAULT now()\n",
    ");\n",
    "\n",
    "INSERT INTO tickets (text) VALUES ('User cannot login');\n",
    "```\n",
    "\n",
    "Any INSERT, UPDATE, DELETE will now emit CDC events.\n",
    "\n",
    "---\n",
    "\n",
    "#### Python Kafka Consumer + Embedding + Vector DB\n",
    "\n",
    "Install required libs:\n",
    "\n",
    "```bash\n",
    "pip install kafka-python langchain-openai faiss-cpu langchain-community\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Python Worker: Consume CDC + Update VectorDB\n",
    "\n",
    "```python\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Initialize embeddings + LLM\n",
    "emb = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n",
    "# Create an empty vectordb\n",
    "vectordb = FAISS.from_texts([\"initial\"], embedding=emb)\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Kafka CDC topic\n",
    "consumer = KafkaConsumer(\n",
    "    \"pg.public.tickets\",\n",
    "    bootstrap_servers=\"localhost:9092\",\n",
    "    auto_offset_reset=\"earliest\",\n",
    "    value_deserializer=lambda m: json.loads(m.decode(\"utf-8\"))\n",
    ")\n",
    "\n",
    "def handle_cdc(payload):\n",
    "    op = payload[\"op\"]\n",
    "\n",
    "    if op == \"c\":   # create\n",
    "        id = str(payload[\"after\"][\"id\"])\n",
    "        text = payload[\"after\"][\"text\"]\n",
    "        vectordb.add_texts([text], ids=[id])\n",
    "        print(f\"[INSERT] id={id}\")\n",
    "\n",
    "    elif op == \"u\":  # update\n",
    "        id = str(payload[\"after\"][\"id\"])\n",
    "        text = payload[\"after\"][\"text\"]\n",
    "        vectordb.delete([id])\n",
    "        vectordb.add_texts([text], ids=[id])\n",
    "        print(f\"[UPDATE] id={id}\")\n",
    "\n",
    "    elif op == \"d\":  # delete\n",
    "        id = str(payload[\"before\"][\"id\"])\n",
    "        vectordb.delete([id])\n",
    "        print(f\"[DELETE] id={id}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Unknown event:\", op)\n",
    "\n",
    "\n",
    "print(\"\\nListening to CDC events...\")\n",
    "for msg in consumer:\n",
    "    payload = msg.value[\"payload\"]\n",
    "    handle_cdc(payload)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Test RAG Answering After CDC Update\n",
    "\n",
    "Place this in a separate terminal:\n",
    "\n",
    "```python\n",
    "query = \"Why is the user unable to log in?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n",
    "```\n",
    "\n",
    "As you modify the Postgres table, answers **automatically update**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example CDC in Action\n",
    "\n",
    "##### 1. Insert a new ticket:\n",
    "\n",
    "```sql\n",
    "INSERT INTO tickets (text) VALUES ('Payment gateway is failing');\n",
    "```\n",
    "\n",
    "Terminal output:\n",
    "\n",
    "```\n",
    "[INSERT] id=2\n",
    "```\n",
    "\n",
    "##### 2. Update ticket:\n",
    "\n",
    "```sql\n",
    "UPDATE tickets SET text='User cannot login due to reset failure' WHERE id=1;\n",
    "```\n",
    "\n",
    "Terminal output:\n",
    "\n",
    "```\n",
    "[UPDATE] id=1\n",
    "```\n",
    "\n",
    "##### 3. Delete ticket:\n",
    "\n",
    "```sql\n",
    "DELETE FROM tickets WHERE id=2;\n",
    "```\n",
    "\n",
    "Terminal:\n",
    "\n",
    "```\n",
    "[DELETE] id=2\n",
    "```\n",
    "\n",
    "Your RAG now reflects the **latest source-of-truth instantly**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9384e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
