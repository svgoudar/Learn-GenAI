{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc4bb91",
   "metadata": {},
   "source": [
    "Here is a **clear, structured explanation of all major RAG (Retrieval-Augmented Generation) types** used in modern Generative AI systems.\n",
    "These are the variants used in production systems (OpenAI, Meta, Google, enterprise RAG, multi-modal RAG, agentic RAG).\n",
    "\n",
    "---\n",
    "\n",
    "# ‚úÖ **Types of RAG (Retrieval-Augmented Generation)**\n",
    "\n",
    "RAG has evolved from a simple retrieval-then-generate pipeline into a family of advanced architectures.\n",
    "\n",
    "Below are the **most important types**, grouped by category.\n",
    "\n",
    "---\n",
    "\n",
    "# üü¶ **1. Basic RAG (Standard RAG / Na√Øve RAG)**\n",
    "\n",
    "This is the simplest pipeline:\n",
    "\n",
    "```\n",
    "Query ‚Üí Embed ‚Üí Vector Search ‚Üí Retrieve Chunks ‚Üí LLM ‚Üí Answer\n",
    "```\n",
    "\n",
    "‚ú¶ Uses embeddings + cosine similarity\n",
    "‚ú¶ Works for basic QA\n",
    "‚ú¶ Fails with long documents or complicated reasoning\n",
    "\n",
    "---\n",
    "\n",
    "# üü© **2. Advanced RAG Variants**\n",
    "\n",
    "These improve retrieval quality, reasoning, accuracy, and reduce hallucination.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.1. RAG-Fusion (Multi-query RAG)**\n",
    "\n",
    "Instead of one query, the system generates **multiple variants**:\n",
    "\n",
    "```\n",
    "Original query ‚Üí LLM rewrites it ‚Üí Multiple queries ‚Üí Merge results\n",
    "```\n",
    "\n",
    "Pros:\n",
    "\n",
    "* handles ambiguous queries\n",
    "* improves recall\n",
    "\n",
    "Used by: **OpenAI Assistants API, LlamaIndex**\n",
    "\n",
    "---\n",
    "\n",
    "## **2.2. HyDE (Hypothetical Document Embeddings)**\n",
    "\n",
    "LLM generates a **fake answer** first ‚Üí embed that ‚Üí retrieve documents close to it.\n",
    "\n",
    "```\n",
    "Query ‚Üí LLM generates hypothetical passage ‚Üí Embed ‚Üí Retrieve\n",
    "```\n",
    "\n",
    "Pros:\n",
    "\n",
    "* retrieval becomes more semantic\n",
    "* reduces noise\n",
    "\n",
    "---\n",
    "\n",
    "## **2.3. Multi-Vector RAG (ColBERT, MLLM-based)**\n",
    "\n",
    "Each document is split into **multiple token-level vectors** (instead of 1 chunk = 1 embedding).\n",
    "\n",
    "Pros:\n",
    "\n",
    "* extremely accurate\n",
    "* great for long context and dense meaning\n",
    "\n",
    "Used by: **ColBERT, BGE-M3, Voyage AI**\n",
    "\n",
    "---\n",
    "\n",
    "## **2.4. Multi-Pass RAG (Iterative RAG / Self-RAG)**\n",
    "\n",
    "LLM checks its own retrieved results and iteratively improves:\n",
    "\n",
    "```\n",
    "Round 1: retrieve + answer  \n",
    "Round 2: verify results ‚Üí retrieve again ‚Üí answer  \n",
    "```\n",
    "\n",
    "Used by: **Self-RAG (Meta, 2023)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.5. Retrieval Re-ranking (Cross-Encoder RAG)**\n",
    "\n",
    "Retriever pulls top 50 candidates ‚Üí a **cross-encoder** re-ranks them.\n",
    "\n",
    "Pros:\n",
    "\n",
    "* best for accuracy\n",
    "* avoids irrelevant chunks\n",
    "\n",
    "---\n",
    "\n",
    "## **2.6. Context Rewriting RAG**\n",
    "\n",
    "LLM rewrites the **query** to match how content is written in documents.\n",
    "\n",
    "Example:\n",
    "User query: ‚ÄúLatest SharePoint updates?‚Äù\n",
    "Rewritten query: ‚ÄúWhat new features were added to Microsoft SharePoint?‚Äù\n",
    "\n",
    "Improves retrieval drastically.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.7. Long-Context RAG (Windowed RAG)**\n",
    "\n",
    "Designed for LLMs with long token limits (e.g., GPT-4.1 with 128K context).\n",
    "\n",
    "Approach:\n",
    "\n",
    "* chunk long documents\n",
    "* place them in context strategically\n",
    "* use sliding windows\n",
    "\n",
    "---\n",
    "\n",
    "# üü® **3. Graph-Based RAG (GraphRAG / KG-RAG)**\n",
    "\n",
    "This is the most advanced and trending RAG architecture.\n",
    "\n",
    "## **GraphRAG**\n",
    "\n",
    "Build a knowledge graph from documents.\n",
    "Queries retrieve **subgraphs**, not chunks.\n",
    "\n",
    "Pros:\n",
    "\n",
    "* handles complex reasoning\n",
    "* captures relationships\n",
    "* retrieves more structured information\n",
    "\n",
    "Used by: **Microsoft GraphRAG**, Neo4J.\n",
    "\n",
    "## **KG-RAG (Knowledge-Graph RAG)**\n",
    "\n",
    "Manual or auto-built knowledge graphs + LLM:\n",
    "\n",
    "* nodes = entities\n",
    "* edges = relationships\n",
    "\n",
    "Improves factual consistency.\n",
    "\n",
    "---\n",
    "\n",
    "# üüß **4. Agentic RAG**\n",
    "\n",
    "RAG with **agents** that can call tools, refine queries, or plan multi-step workflows.\n",
    "\n",
    "Variants:\n",
    "\n",
    "* **ReAct RAG** (LLM thinks + retrieves iteratively)\n",
    "* **Tool-Augmented RAG**\n",
    "* **Planning RAG (AutoGPT-style)**\n",
    "\n",
    "Pros:\n",
    "\n",
    "* can perform multi-hop reasoning\n",
    "* retrieves in steps\n",
    "* executes code/tools during retrieval\n",
    "\n",
    "This is how **ChatGPT-o1**, **Gemini-2**, and **Claude-Opus** reason.\n",
    "\n",
    "---\n",
    "\n",
    "# üü™ **5. Multi-modal RAG**\n",
    "\n",
    "Retrieval includes **text + images + video + audio** embeddings.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* retrieve product images for e-commerce\n",
    "* fetch charts for financial analysis\n",
    "* retrieve screenshots for support bots\n",
    "\n",
    "Uses models like:\n",
    "\n",
    "* CLIP\n",
    "* BLIP\n",
    "* LLaVA\n",
    "* SigLIP\n",
    "* Flamingo\n",
    "\n",
    "---\n",
    "\n",
    "# üü• **6. Domain-Specific RAG Types**\n",
    "\n",
    "---\n",
    "\n",
    "## **6.1. Code RAG**\n",
    "\n",
    "Uses code embeddings (OpenAI, CodeBERT, StarCoder).\n",
    "Great for:\n",
    "\n",
    "* code search\n",
    "* debugging assistance\n",
    "\n",
    "---\n",
    "\n",
    "## **6.2. Legal/Enterprise RAG**\n",
    "\n",
    "Uses structured documents + metadata filtering.\n",
    "Often includes:\n",
    "\n",
    "* access control\n",
    "* audit logs\n",
    "* redaction steps\n",
    "\n",
    "---\n",
    "\n",
    "## **6.3. Real-Time RAG**\n",
    "\n",
    "Continuous indexing + streaming updates.\n",
    "\n",
    "Use cases:\n",
    "\n",
    "* finance\n",
    "* news\n",
    "* security alerts\n",
    "\n",
    "---\n",
    "\n",
    "# üéØ Summary Table\n",
    "\n",
    "| Type             | Best For                           |\n",
    "| ---------------- | ---------------------------------- |\n",
    "| Basic RAG        | Simple Q&A                         |\n",
    "| Multi-query RAG  | Ambiguous queries                  |\n",
    "| HyDE             | Better retrieval using pseudo-docs |\n",
    "| Multi-vector RAG | High-precision search              |\n",
    "| Self-RAG         | Iterative reasoning                |\n",
    "| Re-ranking RAG   | Highest factual accuracy           |\n",
    "| Long-context RAG | Long documents                     |\n",
    "| GraphRAG         | Relationship reasoning             |\n",
    "| Agentic RAG      | Multi-step reasoning               |\n",
    "| Multi-modal RAG  | Images/audio/video                 |\n",
    "| Code RAG         | Code search                        |\n",
    "| Real-time RAG    | Live data                          |\n",
    "\n",
    "Below are **clean, direct problem statements** for every RAG type.\n",
    "Each problem statement describes a **real-world situation** where that specific RAG variant is the correct solution.\n",
    "\n",
    "---\n",
    "\n",
    "# üü¶ **1. Basic RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "A user asks questions about large documents (PDFs, policies, manuals), and you need to retrieve relevant sections and let an LLM answer accurately without loading the full documents into the prompt.\n",
    "\n",
    "---\n",
    "\n",
    "# üü© **2. Advanced RAG Variants**\n",
    "\n",
    "---\n",
    "\n",
    "## **2.1. RAG-Fusion (Multi-query RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "User queries are ambiguous or phrased in different styles, resulting in poor retrieval. You need to rewrite the question into multiple variations to retrieve more diverse and related context.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.2. HyDE (Hypothetical Document Embeddings)**\n",
    "\n",
    "**Problem Statement:**\n",
    "Your vector store contains unstructured or noisy data, and direct embedding of queries retrieves poor matches. You need an LLM-generated ‚Äúhypothetical answer‚Äù to improve semantic matching.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.3. Multi-Vector RAG (ColBERT, BGE-M3)**\n",
    "\n",
    "**Problem Statement:**\n",
    "You need very high accuracy for long, dense, information-heavy text (legal/medical/code), and single-vector-per-chunk retrieval misses fine-grained meaning.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.4. Multi-Pass RAG (Self-RAG / Iterative RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "The system often retrieves *partially relevant* or *wrong* chunks. You need the model to re-check, re-retrieve, and refine retrieval over multiple reasoning steps before finalizing an answer.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.5. Retrieval Re-ranking (Cross-Encoder RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "Your retriever returns too many irrelevant chunks (high recall, low precision). You need a second model to **re-rank** the top 50 candidates to select the most relevant ones.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.6. Query Rewriting (LLM-Refined Query RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "User queries are vague, incomplete, or not aligned with documents (e.g., using slang or shorthand). You need the model to rewrite queries in a more retrieval-friendly form.\n",
    "\n",
    "---\n",
    "\n",
    "## **2.7. Long-Context RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Documents are extremely long (100‚Äì500 pages), and standard chunking fails. You need a system that retrieves large contextual spans or uses sliding windows for long-context LLMs.\n",
    "\n",
    "---\n",
    "\n",
    "# üü® **3. Graph-Based RAG (GraphRAG / KG-RAG)**\n",
    "\n",
    "---\n",
    "\n",
    "## **GraphRAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Your questions require understanding relationships (who ‚Üí did what ‚Üí where ‚Üí why). You need a structured graph retrieval instead of plain chunk lookup.\n",
    "\n",
    "---\n",
    "\n",
    "## **Knowledge-Graph RAG (KG-RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "Your data is highly structured with entities (people, companies, places) and relationships. You need factual consistency and traceability via knowledge graphs.\n",
    "\n",
    "---\n",
    "\n",
    "# üüß **4. Agentic RAG**\n",
    "\n",
    "---\n",
    "\n",
    "## **ReAct RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Questions require multi-step reasoning (e.g., searching multiple sources, verifying intermediate facts). The model must retrieve ‚Üí think ‚Üí retrieve again ‚Üí answer.\n",
    "\n",
    "---\n",
    "\n",
    "## **Tool-Augmented RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Users ask questions that require external tools (database queries, APIs, calculators). You need the LLM to retrieve + call tools dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "## **Planning RAG (Agent RAG)**\n",
    "\n",
    "**Problem Statement:**\n",
    "Tasks involve multiple dependent steps (research ‚Üí extract ‚Üí analyze ‚Üí summarize). You need an agent to plan and execute a multi-step workflow using retrieval at each step.\n",
    "\n",
    "---\n",
    "\n",
    "# üü™ **5. Multi-modal RAG**\n",
    "\n",
    "---\n",
    "\n",
    "## **Image/Text RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Users upload images (screenshots, charts, receipts) and ask questions about them. You need retrieval across both **image embeddings** and **text embeddings**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Video RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Long videos need frame-level retrieval. Users may ask: ‚ÄúAt what time did X happen?‚Äù requiring multimodal search.\n",
    "\n",
    "---\n",
    "\n",
    "# üü• **6. Domain-Specific RAG Types**\n",
    "\n",
    "---\n",
    "\n",
    "## **6.1. Code RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Developers ask questions requiring retrieval from huge codebases. You need code embeddings to retrieve functions, modules, or logic patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## **6.2. Legal/Enterprise RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "Large enterprise documents contain compliance rules. You need precise retrieval with metadata filters and access control (ACLs).\n",
    "\n",
    "---\n",
    "\n",
    "## **6.3. Real-Time RAG**\n",
    "\n",
    "**Problem Statement:**\n",
    "You need to answer questions on constantly updating data (news, stock markets, logs). Retrieval must reflect new information within seconds/minutes.\n",
    "\n",
    "---\n",
    "\n",
    "# ‚≠ê **Summary Table ‚Äî Problem Statement by Type**\n",
    "\n",
    "| RAG Type             | Problem It Solves                            |\n",
    "| -------------------- | -------------------------------------------- |\n",
    "| Basic RAG            | Retrieve relevant text chunks for QA         |\n",
    "| Multi-query RAG      | Ambiguous queries ‚Üí poor retrieval           |\n",
    "| HyDE                 | Query not semantically close to documents    |\n",
    "| Multi-vector RAG     | Need high-precision retrieval at token level |\n",
    "| Self-RAG             | Need verification + iterative improvement    |\n",
    "| Re-ranking RAG       | Need higher precision in retrieved chunks    |\n",
    "| Query rewriting      | Users ask vague or mismatched queries        |\n",
    "| Long-context RAG     | Need retrieval from very long documents      |\n",
    "| GraphRAG             | Need relationship-level reasoning            |\n",
    "| KG-RAG               | Need structured entity-level reasoning       |\n",
    "| ReAct RAG            | Need multi-step retrieval + reasoning        |\n",
    "| Tool-Augmented RAG   | Need external tool/API calling               |\n",
    "| Planning RAG         | Need multi-step workflows with retrieval     |\n",
    "| Multi-modal RAG      | Need retrieval across images/audio/video     |\n",
    "| Code RAG             | Need codebase retrieval                      |\n",
    "| Legal/Enterprise RAG | Need strict accuracy + metadata filtering    |\n",
    "| Real-Time RAG        | Need retrieval from streaming data           |\n",
    "\n",
    "---\n",
    "\n",
    "If you want next:\n",
    "\n",
    "* **Diagrams of each RAG type**\n",
    "* **Python code examples**\n",
    "* **Which RAG type to use for your use case**\n",
    "* **Pros/cons of each RAG type**\n",
    "\n",
    "Tell me.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab67e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
