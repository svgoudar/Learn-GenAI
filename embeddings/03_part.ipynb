{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c573378",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "## Vector Normalization\n",
    "\n",
    "### **Definition**\n",
    "\n",
    "Vector normalization means scaling a vector so that its **length (magnitude)** becomes **1**, without changing its **direction**.\n",
    "\n",
    "For a vector ( v ):\n",
    "$$\n",
    "v_{\\text{norm}} = \\frac{v}{|v|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "|v| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\n",
    "$$\n",
    "\n",
    "After normalization:\n",
    "\n",
    "```\n",
    "||v_norm|| = 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Normalization Is Very Important in Generative AI**\n",
    "\n",
    "LLMs and RAG systems frequently use **cosine similarity** to compare embeddings.\n",
    "\n",
    "Cosine similarity compares **direction**, not magnitude.\n",
    "\n",
    "But if vectors have inconsistent magnitudes, similarity becomes unstable.\n",
    "Normalization fixes this.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Ensures Fair Comparison Between Embeddings**\n",
    "\n",
    "Two semantically identical embeddings may have different lengths:\n",
    "\n",
    "```\n",
    "v1 = [0.5, 1.0, -0.3]\n",
    "v2 = [5, 10, -3]\n",
    "```\n",
    "\n",
    "Meaning is same → magnitudes different.\n",
    "\n",
    "Without normalization:\n",
    "\n",
    "* cosine similarity is incorrect\n",
    "* retrieval quality becomes unstable\n",
    "\n",
    "After normalization:\n",
    "\n",
    "```\n",
    "v1_norm == v2_norm\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Required for Correct Cosine Similarity**\n",
    "\n",
    "Cosine similarity formula:\n",
    "\n",
    "$$\n",
    "\\frac{v_1 \\cdot v_2}{|v_1| |v_2|}\n",
    "$$\n",
    "\n",
    "If you normalize first:\n",
    "\n",
    "$$\n",
    "\\text{cosine_sim}(v_1, v_2) = v_{1_{\\text{norm}}} \\cdot v_{2_{\\text{norm}}}\n",
    "$$\n",
    "\n",
    "Dot product becomes equal to cosine similarity.\n",
    "This speeds up vector search libraries like FAISS, Qdrant, Weaviate.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Improves Performance of Vector Databases**\n",
    "\n",
    "Vector DBs expect **unit vectors** for better:\n",
    "\n",
    "* clustering\n",
    "* indexing\n",
    "* ANN search accuracy\n",
    "\n",
    "Databases that recommend normalization:\n",
    "\n",
    "* FAISS\n",
    "* Pinecone\n",
    "* Qdrant\n",
    "* Milvus\n",
    "* Weaviate\n",
    "\n",
    "Storing non-normalized vectors → poor retrieval and hallucinations in RAG.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Prevents Embedding Drift**\n",
    "\n",
    "Models sometimes output slightly different scales due to:\n",
    "\n",
    "* hardware differences (GPU vs CPU)\n",
    "* quantization\n",
    "* updated model checkpoints\n",
    "\n",
    "Normalization removes scaling differences → stable retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Necessary for CLIP / VLMs**\n",
    "\n",
    "CLIP embeddings must be normalized before:\n",
    "\n",
    "* image–text matching\n",
    "* image search\n",
    "* generating captions\n",
    "\n",
    "Otherwise matching breaks.\n",
    "\n",
    "---\n",
    "\n",
    "**Intuition**\n",
    "\n",
    "Normalization makes vectors lie on a **unit sphere**.\n",
    "\n",
    "Visual analogy:\n",
    "\n",
    "* different lengths → random points in space\n",
    "* same length → all vectors lie on surface of a sphere → only direction matters\n",
    "\n",
    "LLM embeddings work best when compared by direction.\n",
    "\n",
    "---\n",
    "\n",
    "### **Python Implementation**\n",
    "\n",
    "#### **NumPy**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def normalize(v):\n",
    "    return v / np.linalg.norm(v)\n",
    "\n",
    "v = np.array([3, 4, 0])\n",
    "print(normalize(v))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **PyTorch**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "v = torch.tensor([3.0, 4.0, 0.0])\n",
    "v_norm = v / torch.norm(v)\n",
    "\n",
    "print(v_norm)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Normalize Many Vectors (RAG use case)**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "matrix = np.array([\n",
    "    [0.2, 0.5, -0.1],\n",
    "    [3.0, 6.0, -1.8],\n",
    "    [-0.4, 0.1, 0.9]\n",
    "])\n",
    "\n",
    "normalized_matrix = normalize(matrix, axis=1)\n",
    "print(normalized_matrix)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Final Summary (Cheat Sheet)**\n",
    "\n",
    "| Concept      | Explanation                                            |\n",
    "| ------------ | ------------------------------------------------------ |\n",
    "| **What**     | Scaling vectors to length = 1                          |\n",
    "| **Why**      | Stable cosine similarity, better search                |\n",
    "| **Used in**  | RAG, semantic search, CLIP, VLMs, embeddings           |\n",
    "| **Benefits** | Faster ANN, better accuracy, drift prevention          |\n",
    "| **Key idea** | Make embeddings comparable by direction, not magnitude |\n",
    "\n",
    "Normalization is **mandatory** whenever embeddings are used for retrieval or similarity."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
