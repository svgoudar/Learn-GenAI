{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b6efdb",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Dimensionality\n",
    "\n",
    "\n",
    "\n",
    "Dimensionality = the **number of features** (values) in an embedding vector.\n",
    "\n",
    "Example:\n",
    "\n",
    "* A 768-dimensional embedding → vector of length 768\n",
    "* A 4096-dimensional embedding → vector of length 4096\n",
    "\n",
    "Formally:\n",
    "\n",
    "```\n",
    "Embedding = [v1, v2, v3, ..., vD]\n",
    "Where D = dimensionality\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Dimensionality Matters in Generative AI**\n",
    "\n",
    "Embeddings represent meaning as points in a high-dimensional semantic space.\n",
    "Dimensionality determines **how much information** an embedding can store.\n",
    "\n",
    "Higher dimensionality → richer representation\n",
    "Lower dimensionality → faster search, cheaper storage\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Dimensionality Determines Model Expressiveness**\n",
    "\n",
    "More dimensions let embeddings store:\n",
    "\n",
    "* semantic features\n",
    "* syntactic features\n",
    "* world knowledge patterns\n",
    "* relationships\n",
    "* modality-specific details (vision/audio)\n",
    "\n",
    "Example:\n",
    "LLaMA & GPT models store **everything they know** inside thousands of embedding dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Dimensionality Affects RAG Search Quality**\n",
    "\n",
    "RAG systems store embeddings in vector databases.\n",
    "\n",
    "High dimensions:\n",
    "\n",
    "* better retrieval accuracy\n",
    "* lower risk of collisions (two unrelated embeddings overlapping)\n",
    "\n",
    "Low dimensions:\n",
    "\n",
    "* faster vector search\n",
    "* smaller storage\n",
    "* lower latency\n",
    "\n",
    "Choosing dimensionality is a **trade-off**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Dimensionality Affects Memory & Storage**\n",
    "\n",
    "Example:\n",
    "Storing 1 million embeddings:\n",
    "\n",
    "| Dimension | Size (FP32)  | Storage |\n",
    "| --------- | ------------ | ------- |\n",
    "| 384       | ~1.5 KB each | ~1.5 GB |\n",
    "| 1024      | ~4 KB each   | ~4 GB   |\n",
    "| 4096      | ~16 KB each  | ~16 GB  |\n",
    "\n",
    "Large embeddings → large vector DBs → expensive retrieval.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Dimensionality Affects ANN Search Speed**\n",
    "\n",
    "High-dim vectors require more computation for:\n",
    "\n",
    "* dot product\n",
    "* cosine similarity\n",
    "* Faiss/HNSW graph traversal\n",
    "\n",
    "This is called the **curse of dimensionality**.\n",
    "\n",
    "Thus:\n",
    "\n",
    "* 768-dim (SBERT) → faster\n",
    "* 1536-dim (OpenAI) → moderate\n",
    "* 4096-dim (LLaMA token embeddings) → slower\n",
    "\n",
    "ANN (Approx Nearest Neighbor) algorithms suffer as D↑.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Dimensionality Depends on the Model Architecture**\n",
    "\n",
    "Examples:\n",
    "\n",
    "| Model                             | Embedding Dim              |\n",
    "| --------------------------------- | -------------------------- |\n",
    "| **Sentence-BERT**                 | 768                        |\n",
    "| **E5-Large**                      | 1024                       |\n",
    "| **OpenAI text-embedding-3-small** | 1536                       |\n",
    "| **CLIP ViT-L**                    | 768 / 1024                 |\n",
    "| **LLaMA-3 70B embeddings**        | 4096                       |\n",
    "| **GPT-4 embeddings**              | undisclosed but very large |\n",
    "\n",
    "Larger models → larger vector spaces.\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Dimensionality Impacts Cross-Modal Models (CLIP / VLMs)**\n",
    "\n",
    "In vision-language models (CLIP, BLIP, LLaVA):\n",
    "\n",
    "* Text embeddings have X dimensions\n",
    "* Image embeddings have X dimensions\n",
    "\n",
    "Both must match to compute cosine similarity.\n",
    "\n",
    "Thus:\n",
    "\n",
    "```\n",
    "image_dim == text_dim\n",
    "```\n",
    "\n",
    "Dimensionality ensures alignment between modalities.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Dimensionality Is Fixed Per Model**\n",
    "\n",
    "You **cannot change** embedding dimension for:\n",
    "\n",
    "* OpenAI embeddings\n",
    "* HuggingFace models\n",
    "* CLIP\n",
    "* SBERT\n",
    "\n",
    "Because the embedding dimension is tied to:\n",
    "\n",
    "* neural architecture\n",
    "* projection layers\n",
    "* training checkpoints\n",
    "\n",
    "Changing dimension = retraining the model.\n",
    "\n",
    "---\n",
    "\n",
    "#### Python Example: Checking Dimensionality\n",
    "\n",
    "Using Sentence-BERT:\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "emb = model.encode(\"hello\")\n",
    "\n",
    "print(\"Embedding shape:\", emb.shape)\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "Embedding shape: (384,)\n",
    "```\n",
    "\n",
    "Using OpenAI embeddings:\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "res = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=\"Generative AI\"\n",
    ")\n",
    "\n",
    "print(len(res.data[0].embedding))\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "1536\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "\n",
    "| Concept                        | Explanation                                |\n",
    "| ------------------------------ | ------------------------------------------ |\n",
    "| **Dimensionality**             | Number of features in an embedding vector  |\n",
    "| **High dimension (1024–4096)** | Rich semantics, slower search              |\n",
    "| **Low dimension (256–768)**    | Fast, cheaper, less expressive             |\n",
    "| **Used in**                    | LLMs, RAG, CLIP, Multimodal AI             |\n",
    "| **Trade-offs**                 | Accuracy vs. speed vs. storage             |\n",
    "| **Fixed**                      | You cannot change across pretrained models |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
