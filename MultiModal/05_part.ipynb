{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a75fcb",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "\n",
    "## Text-to-Speech (TTS)\n",
    "\n",
    "Text-to-Speech converts **written text** into **natural-sounding speech**.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Input: \"Hello, how are you?\"\n",
    "Output: Audio waveform of a human saying it\n",
    "```\n",
    "\n",
    "TTS is used in:\n",
    "\n",
    "* Voice assistants (Alexa, Siri, Google Assistant)\n",
    "* IVR / customer service bots\n",
    "* Audiobooks\n",
    "* Accessibility (screen readers)\n",
    "* Multimodal LLMs (GPT-4o, Gemini, Deepgram, Coqui)\n",
    "\n",
    "---\n",
    "\n",
    "### Why TTS Is Hard\n",
    "\n",
    "Speech is extremely complex:\n",
    "\n",
    "* tone\n",
    "* rhythm\n",
    "* pitch\n",
    "* prosody (natural expression)\n",
    "* emotion\n",
    "* accent\n",
    "* pausing and timing\n",
    "* context awareness\n",
    "\n",
    "TTS must generate audio that sounds **human**, not robotic.\n",
    "\n",
    "---\n",
    "\n",
    "### **How Text-to-Speech Works — 3-Stage Architecture**\n",
    "\n",
    "Modern TTS systems have a **three-stage pipeline**:\n",
    "\n",
    "---\n",
    "\n",
    "#### Text Processing (Linguistic Frontend)\n",
    "\n",
    "The model converts text into linguistic units.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Normalization (“$100” → “one hundred dollars”)\n",
    "* Expand abbreviations (“Dr.” → “doctor”)\n",
    "* Tokenization\n",
    "* Convert text → phonemes\n",
    "* Prosody prediction (where to pause)\n",
    "\n",
    "This produces a sequence of **phoneme IDs** or **linguistic tokens**.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "\"Hello\" → [\"HH\", \"AH\", \"L\", \"OW\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Acoustic Model\n",
    "\n",
    "The model predicts **acoustic features** from text/phonemes.\n",
    "Typically:\n",
    "\n",
    "* **Mel spectrograms** (image-like 2D sound representation)\n",
    "\n",
    "Old models:\n",
    "\n",
    "* Tacotron, Tacotron2\n",
    "* FastSpeech, FastSpeech2\n",
    "\n",
    "New models:\n",
    "\n",
    "* VITS (end-to-end)\n",
    "* SpeechLM\n",
    "* GPT-4o TTS\n",
    "\n",
    "Output example (mel spectrogram):\n",
    "\n",
    "```\n",
    "(80 mel bins × 400 frames)\n",
    "```\n",
    "\n",
    "This spectrogram describes:\n",
    "\n",
    "* pitch\n",
    "* loudness\n",
    "* pronunciation\n",
    "* duration\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Vocoder\n",
    "\n",
    "The vocoder converts the spectrogram → raw audio waveform.\n",
    "\n",
    "Popular vocoders:\n",
    "\n",
    "* **WaveGlow**\n",
    "* **WaveNet (Google)**\n",
    "* **HiFi-GAN** → most widely used today\n",
    "* **RefineGAN**\n",
    "* **WaveRNN**\n",
    "\n",
    "Input:\n",
    "\n",
    "```\n",
    "Mel spectrogram\n",
    "```\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "16000 samples per second (PCM waveform)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Modern End-to-End TTS Models\n",
    "\n",
    "#### **1. VITS (Very High Quality)**\n",
    "\n",
    "* Combines spectrogram generation + vocoder in one network\n",
    "* State of the art in open source\n",
    "* High realism, natural prosody\n",
    "\n",
    "#### **2. FastSpeech 2 + HiFi-GAN**\n",
    "\n",
    "* Extremely fast\n",
    "* Production-friendly\n",
    "* Good quality\n",
    "\n",
    "#### **3. Neural Codec Models (GPT-4o, Meta VoiceBox, Google AudioLM)**\n",
    "\n",
    "* Use audio tokens instead of spectrograms\n",
    "* Model speech like text\n",
    "* Can clone voices, emotions, accents\n",
    "\n",
    "This is why GPT-4o TTS sounds extremely natural.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuition Behind TTS\n",
    "\n",
    "#### Think of TTS like animating a human voice.\n",
    "\n",
    "Text → plan how a human would say it → generate acoustic patterns → convert to audio.\n",
    "\n",
    "TTS must decide:\n",
    "\n",
    "* how long each phoneme lasts\n",
    "* how pitch rises/falls\n",
    "* where pauses go\n",
    "* how loud each syllable should be\n",
    "\n",
    "Good TTS mimics human speech patterns.\n",
    "\n",
    "---\n",
    "\n",
    "# ⭐ Demo — Text to Speech Using Python (Easy)\n",
    "\n",
    "### Install TTS (Coqui)\n",
    "\n",
    "```bash\n",
    "pip install TTS\n",
    "```\n",
    "\n",
    "### Simple Example\n",
    "\n",
    "```python\n",
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS(\"tts_models/en/ljspeech/tacotron2-DDC\")  # model name\n",
    "tts.tts_to_file(text=\"Hello! This is a text to speech demo.\", file_path=\"output.wav\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Demo — Text to Speech Using Transformers + SpeechT5\n",
    "\n",
    "```bash\n",
    "pip install transformers datasets soundfile\n",
    "```\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from transformers import SpeechT5ForTextToSpeech, SpeechT5Processor\n",
    "\n",
    "processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "\n",
    "inputs = processor(text=\"Hello world!\", return_tensors=\"pt\")\n",
    "\n",
    "speech = model.generate_speech(inputs[\"input_ids\"])\n",
    "sf.write(\"speech.wav\", speech.numpy(), 16000)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### What Makes a TTS Model Good?\n",
    "\n",
    "#### 1. **Natural prosody**\n",
    "\n",
    "Sound like human, not flat.\n",
    "\n",
    "#### 2. **Emotion control**\n",
    "\n",
    "Happy, sad, excited.\n",
    "\n",
    "#### 3. **Contextual awareness**\n",
    "\n",
    "Reads sentences intelligently.\n",
    "\n",
    "#### 4. **Speaker identity**\n",
    "\n",
    "Consistent voice across long paragraphs.\n",
    "\n",
    "#### 5. **Noise robustness**\n",
    "\n",
    "#### 6. **Fast inference**\n",
    "\n",
    "---\n",
    "\n",
    "**One-Sentence Summary**\n",
    "\n",
    "**Text-to-Speech converts text → phonemes → mel spectrogram → audio waveform using neural networks like Tacotron, FastSpeech, VITS, or neural codec language models for human-like speech.**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
