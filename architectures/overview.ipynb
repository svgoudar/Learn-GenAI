{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf7132e",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```\n",
    "\n",
    "## Architecture\n",
    "\n",
    "### Autoencoders (AE)\n",
    "\n",
    "#### Core Idea:\n",
    "\n",
    "Autoencoders learn to **compress (encode)** data into a lower-dimensional latent space and then **reconstruct (decode)** it back to the original form.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    "* **Encoder:** Converts input data (e.g., an image) into a compact latent vector (representation).\n",
    "* **Decoder:** Reconstructs the input data from this latent vector.\n",
    "* **Training goal:** Minimize the reconstruction error between input and output.\n",
    "\n",
    "#### Generative Variant:\n",
    "\n",
    "**Variational Autoencoder (VAE)** — Instead of deterministic encoding, it learns a *probability distribution* of latent variables, allowing random sampling for new data generation.\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "* Image denoising and inpainting\n",
    "* Anomaly detection\n",
    "* Generating new faces, text, or molecular structures\n",
    "\n",
    "---\n",
    "\n",
    "### Generative Adversarial Networks (GANs)\n",
    "\n",
    "#### **Core Idea:**\n",
    "\n",
    "GANs use **two networks competing against each other**:\n",
    "\n",
    "* **Generator (G):** Creates fake samples.\n",
    "* **Discriminator (D):** Classifies samples as real or fake.\n",
    "\n",
    "Through competition, the generator learns to produce data indistinguishable from real samples.\n",
    "\n",
    "#### **Workflow:**\n",
    "\n",
    "1. Generator produces fake data from random noise.\n",
    "2. Discriminator evaluates real vs. fake.\n",
    "3. Both improve iteratively — the generator gets better at “fooling” the discriminator.\n",
    "\n",
    "#### **Key Variants:**\n",
    "\n",
    "* **DCGAN:** Uses convolution layers for image synthesis.\n",
    "* **CycleGAN:** Translates between domains (e.g., horse ↔ zebra).\n",
    "* **StyleGAN:** Generates high-resolution, photorealistic faces.\n",
    "\n",
    "#### **Applications:**\n",
    "\n",
    "* Image and video generation\n",
    "* Deepfake creation (and detection)\n",
    "* Image-to-image translation\n",
    "\n",
    "---\n",
    "\n",
    "### Diffusion Models\n",
    "\n",
    "#### Core Idea:\n",
    "\n",
    "Start with random **noise** and gradually **denoise** it into meaningful data.\n",
    "They model the *reverse of a noise process* that destroys data during training.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    "1. Add Gaussian noise to data until it becomes random noise.\n",
    "2. Train a neural network to learn the reverse denoising steps.\n",
    "3. Generate new samples by starting from random noise and reversing the process.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "* **DDPM (Denoising Diffusion Probabilistic Model)**\n",
    "* **Stable Diffusion** (text-to-image generation)\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "* Text-to-image generation (e.g., DALL·E, Midjourney)\n",
    "* Super-resolution\n",
    "* Image editing and inpainting\n",
    "\n",
    "---\n",
    "\n",
    "### Flow-Based Models\n",
    "\n",
    "#### Core Idea:\n",
    "\n",
    "Learn an **invertible transformation** between data space and a simple latent distribution (like Gaussian).\n",
    "They allow *exact likelihood computation* and *reversible generation*.\n",
    "\n",
    "#### Workflow:\n",
    "\n",
    "* Forward pass: Data → Latent space (compression).\n",
    "* Reverse pass: Latent → Data (generation).\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "* **RealNVP (Non-Volume Preserving Transformations)**\n",
    "* **Glow (OpenAI)**\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "* High-quality image synthesis\n",
    "* Anomaly detection\n",
    "* Density estimation\n",
    "\n",
    "---\n",
    "\n",
    "### Transformer-Based Generative Models\n",
    "\n",
    "#### Core Idea:\n",
    "\n",
    "Use **self-attention** mechanisms to process entire sequences (text, image patches, audio) in parallel.\n",
    "They predict the next element (token or pixel) in a sequence given the previous ones.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "* **GPT family:** Text generation (OpenAI)\n",
    "* **BERT / T5:** Language understanding and generation\n",
    "* **DALL·E / Imagen:** Text-to-image generation\n",
    "* **Music Transformer:** Music generation\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "* Text generation and completion\n",
    "* Code generation (e.g., GitHub Copilot)\n",
    "* Text-to-image and text-to-video tasks\n",
    "\n",
    "---\n",
    "\n",
    "### Energy-Based Models (EBMs)\n",
    "\n",
    "#### Core Idea:\n",
    "\n",
    "EBMs assign an **energy score** to each possible data configuration.\n",
    "Low energy = more likely (realistic) data.\n",
    "Generation happens by sampling from this energy function.\n",
    "\n",
    "#### Examples:\n",
    "\n",
    "* Boltzmann Machines\n",
    "* Deep Energy Models\n",
    "\n",
    "#### Applications:\n",
    "\n",
    "* Representation learning\n",
    "* Anomaly detection\n",
    "* Unsupervised generative modeling\n",
    "\n",
    "---\n",
    "\n",
    "### Hybrid Architectures\n",
    "\n",
    "Modern generative models often **combine multiple approaches** for better quality and control:\n",
    "\n",
    "* **VAE + GAN:** Combines stability of VAEs and realism of GANs (e.g., VAE-GAN).\n",
    "* **Transformer + Diffusion:** Powers multimodal models like **DALL·E 3** and **Stable Diffusion XL**.\n",
    "* **RNN + VAE:** Used in music and sequence generation.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Table**\n",
    "\n",
    "| **Architecture**  | **Core Principle**                        | **Representative Models**        | **Applications**                   |\n",
    "| ----------------- | ----------------------------------------- | -------------------------------- | ---------------------------------- |\n",
    "| Autoencoder / VAE | Latent-space compression & reconstruction | VAE, β-VAE                       | Data synthesis, anomaly detection  |\n",
    "| GAN               | Adversarial competition                   | DCGAN, StyleGAN, CycleGAN        | Realistic image/video generation   |\n",
    "| Diffusion Model   | Reverse noise-to-data                     | Stable Diffusion, DDPM           | Text-to-image, super-resolution    |\n",
    "| Flow-Based        | Invertible transformations                | RealNVP, Glow                    | Exact likelihood, image generation |\n",
    "| Transformer       | Attention-based sequence modeling         | GPT, DALL·E, T5                  | Text, image, code generation       |\n",
    "| EBM               | Energy landscape modeling                 | Boltzmann Machine                | Representation learning            |\n",
    "| Hybrid            | Combined strengths of multiple models     | VAE-GAN, Diffusion + Transformer | Multimodal generation              |\n",
    "\n",
    "```{dropdown} Click here for Sections\n",
    "```{tableofcontents}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
